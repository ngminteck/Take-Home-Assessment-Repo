{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a651d6bc-6ef6-429e-b52f-f1c82a8dd04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (2.7.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.40.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.15.1 in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.23.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2023.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.15.1->sentence-transformers) (4.9.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.34.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.15.1->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\ng_mi\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U sentence-transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fb6332b-e191-45ae-9ca1-c5a84176ee7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ng_mi\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "C:\\Users\\ng_mi\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved dictionary to 2018-2019 mapping.json\n",
      "Saved dictionary to 2019-2020 mapping.json\n",
      "Saved dictionary to 2020-2021 mapping.json\n",
      "Saved dictionary to 2021-2022 mapping.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "import re\n",
    "\n",
    "model = SentenceTransformer('multi-qa-MiniLM-L6-cos-v1')\n",
    "\n",
    "with open('Assignments/assets/column_names.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "def extract_info(year_data):\n",
    "    info_dict = {}\n",
    "    for chapter, info_list in year_data.items():\n",
    "        info_dict[chapter] = info_list\n",
    "    return info_dict\n",
    "\n",
    "def process_exact_mapping(from_readonly_dict,to_readonly_dict):\n",
    "    from_processed_dict = from_readonly_dict\n",
    "    to_processed_dict = to_readonly_dict\n",
    "    extact_mapping_dict = {}\n",
    "    \n",
    "    for worksheet , column_list in from_readonly_dict.items():\n",
    "        if worksheet in to_readonly_dict:\n",
    "            match_dict = {question: question for question in column_list if question in to_readonly_dict[worksheet]}\n",
    "            from_processed_dict[worksheet] = list(set(from_processed_dict[worksheet]) - set(match_dict.keys()))\n",
    "            to_processed_dict[worksheet] = list(set(to_processed_dict[worksheet]) - set(match_dict.values()))\n",
    "            info_dict = {\"Mapped Worksheet\":worksheet ,\"Mapped Column\" : match_dict }\n",
    "            extact_mapping_dict[worksheet] = info_dict\n",
    "        \n",
    "    from_processed_dict = {k: v for k, v in from_processed_dict.items() if v}\n",
    "    to_processed_dict = {k: v for k, v in to_processed_dict.items() if v}\n",
    "    return extact_mapping_dict, from_processed_dict, to_processed_dict\n",
    "\n",
    "def process_same_worksheet_similar_context_mapping(from_readonly_dict,to_readonly_dict):\n",
    "    from_processed_dict = from_readonly_dict\n",
    "    to_processed_dict = to_readonly_dict\n",
    "    suggestion_mapping_dict = {}\n",
    "    \n",
    "    for worksheet , column_list in from_readonly_dict.items():\n",
    "        if worksheet in to_readonly_dict:\n",
    "            from_question_list = from_processed_dict[worksheet]\n",
    "            suggestion_dict = {}\n",
    "            for i in range(len(from_question_list)):\n",
    "                if worksheet not in to_processed_dict:\n",
    "                    break\n",
    "                to_question_list = to_processed_dict[worksheet]\n",
    "                to_embedding = model.encode(to_question_list)\n",
    "                from_embedding = model.encode(from_question_list[i])\n",
    "                sims = util.cos_sim(from_embedding, to_embedding)\n",
    "                top_results = torch.topk(sims, 1)\n",
    "                scores = top_results[0].numpy()\n",
    "                indices = top_results[1].numpy()\n",
    "                for score, idx in zip(scores[0], indices[0]):\n",
    "                    if score >= 0.9:\n",
    "                        suggestion_dict[from_question_list[i]]= to_question_list[idx.item()]\n",
    "                        from_processed_dict[worksheet] = list(set(from_processed_dict[worksheet]) - set(suggestion_dict.keys()))\n",
    "                        to_processed_dict[worksheet] = list(set(to_processed_dict[worksheet]) - set(suggestion_dict.values()))\n",
    "                       \n",
    "                        to_processed_dict = {k: v for k, v in to_processed_dict.items() if v}\n",
    "                    # print(from_question_list[i])\n",
    "                    # print(to_question_list[idx.item()], \"(Score: {:.4f})\".format(score.item()))\n",
    "                #print(\"\\n\")\n",
    "            if suggestion_dict:\n",
    "                info_dict = {\"Mapped Worksheet\":worksheet ,\"Mapped Column\" : suggestion_dict }\n",
    "                suggestion_mapping_dict[worksheet] = info_dict\n",
    "    \n",
    "    from_processed_dict = {k: v for k, v in from_processed_dict.items() if v}\n",
    "    return suggestion_mapping_dict, from_processed_dict, to_processed_dict\n",
    "\n",
    "def search_keys(dictionary, pattern):\n",
    "    return [key for key in dictionary.keys() if re.search(pattern, key)]\n",
    "\n",
    "def process_cross_worksheet_extact_context_mapping(from_processed_dict,to_processed_dict, unprocessed_from_worksheet_dict, unprocessed_to_worksheet_dict):\n",
    "    suggestion_mapping_dict = {}\n",
    " \n",
    "    for worksheet , column_list in unprocessed_from_worksheet_dict.items():\n",
    "        if not unprocessed_to_worksheet_dict: \n",
    "            break\n",
    "        key_list = list(unprocessed_to_worksheet_dict.keys())\n",
    "        to_embedding = model.encode(key_list)\n",
    "        from_embedding = model.encode(worksheet)\n",
    "        sims = util.cos_sim(from_embedding, to_embedding)\n",
    "        top_results = torch.topk(sims, len(key_list))\n",
    "        scores = top_results[0].numpy()\n",
    "        indices = top_results[1].numpy()\n",
    "        #print(worksheet)\n",
    "        for score, idx in zip(scores[0], indices[0]):\n",
    "            if score >= 0.9 and column_list == unprocessed_to_worksheet_dict[key_list[idx.item()]]:\n",
    "                mapped_column_dict = dict(zip(column_list, unprocessed_to_worksheet_dict[key_list[idx.item()]]))\n",
    "                info_dict = {\"Mapped Worksheet\":key_list[idx.item()] ,\"Mapped Column\" : mapped_column_dict }\n",
    "                suggestion_mapping_dict[worksheet] = info_dict\n",
    "                del from_processed_dict[worksheet]\n",
    "                del to_processed_dict[key_list[idx.item()]]\n",
    "                del unprocessed_to_worksheet_dict[key_list[idx.item()]]\n",
    "                break\n",
    "                \n",
    "            #print(key_list[idx.item()], \"(Score: {:.4f})\".format(score.item()))\n",
    "        #print(\"\\n\")    \n",
    "    return suggestion_mapping_dict, from_processed_dict, to_processed_dict\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def mapping(year1,year2):\n",
    "    result_dict = {\"Extact Mapping\": None, \"Same Worksheet Similar Context Mapping\": None, \"Cross Worksheet Extact Context Mapping\": None, year1 + \" Remainder\": None,  year2 + \" Remainder\": None }\n",
    "    json_file_path = year1 + \"-\" + year2 + \" mapping.json\"\n",
    "    from_dict = extract_info(data[year1])\n",
    "    to_dict = extract_info(data[year2])\n",
    "    unprocessed_from_worksheet_dict = from_dict\n",
    "    unprocessed_to_worksheet_dict = to_dict\n",
    "                                       \n",
    "    result_dict[\"Extact Mapping\"], from_dict, to_dict = process_exact_mapping(from_dict, to_dict)\n",
    "    result_dict[\"Same Worksheet Similar Context Mapping\"], from_dict, to_dict = process_same_worksheet_similar_context_mapping(from_dict, to_dict)\n",
    "    \n",
    "    unprocessed_from_worksheet_dict = {k: v for k, v in unprocessed_from_worksheet_dict.items() if k not in result_dict[\"Extact Mapping\"]}\n",
    "    unprocessed_to_worksheet_dict = {k: v for k, v in unprocessed_to_worksheet_dict.items() if k not in result_dict[\"Extact Mapping\"]}\n",
    "    unprocessed_from_worksheet_dict = {k: v for k, v in unprocessed_from_worksheet_dict.items() if k not in result_dict[\"Same Worksheet Similar Context Mapping\"]}\n",
    "    unprocessed_to_worksheet_dict = {k: v for k, v in unprocessed_to_worksheet_dict.items() if k not in result_dict[\"Same Worksheet Similar Context Mapping\"]}\n",
    "    result_dict[\"Cross Worksheet Extact Context Mapping\"], from_dict, to_dict = process_cross_worksheet_extact_context_mapping(from_dict, to_dict, unprocessed_from_worksheet_dict, unprocessed_to_worksheet_dict )\n",
    "    \n",
    "    result_dict[year1 + \" Remainder\"] = from_dict\n",
    "    result_dict[year2 + \" Remainder\"] = to_dict\n",
    "    \n",
    "    \n",
    "    # Save the dictionary to the JSON file\n",
    "    with open(json_file_path, 'w') as json_file:\n",
    "        json.dump(result_dict, json_file, indent=4)\n",
    "\n",
    "    print(f\"Saved dictionary to {json_file_path}\")\n",
    "    \n",
    "mapping(\"2018\",\"2019\")\n",
    "mapping(\"2019\",\"2020\")\n",
    "mapping(\"2020\",\"2021\")\n",
    "mapping(\"2021\",\"2022\")\n",
    "       \n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58651b88-d6d6-471d-aa55-5b7f619d0146",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
